{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e1f6c7-4425-4b41-a290-e3ef52b744ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy, Mean\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a2db5fd-2e4d-4af2-a344-f2633ab48528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 1\n",
      "Train Loss : 0.2127\t Train Accuracy: 92.20%\n",
      " Validation Loss : 0.1512\t Validation Accuracy: 93.20%\n",
      "\n",
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 2\n",
      "Train Loss : 0.1690\t Train Accuracy: 93.10%\n",
      " Validation Loss : 0.1461\t Validation Accuracy: 93.20%\n",
      "\n",
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 3\n",
      "Train Loss : 0.1678\t Train Accuracy: 92.00%\n",
      " Validation Loss : 0.1449\t Validation Accuracy: 93.40%\n",
      "\n",
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 4\n",
      "Train Loss : 0.1662\t Train Accuracy: 92.60%\n",
      " Validation Loss : 0.1419\t Validation Accuracy: 92.90%\n",
      "\n",
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 5\n",
      "Train Loss : 0.1639\t Train Accuracy: 92.70%\n",
      " Validation Loss : 0.1782\t Validation Accuracy: 92.30%\n",
      "\n",
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 6\n",
      "Train Loss : 0.1661\t Train Accuracy: 92.60%\n",
      " Validation Loss : 0.1435\t Validation Accuracy: 93.20%\n",
      "\n",
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 7\n",
      "Train Loss : 0.1654\t Train Accuracy: 92.80%\n",
      " Validation Loss : 0.1411\t Validation Accuracy: 93.00%\n",
      "\n",
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 8\n",
      "Train Loss : 0.1678\t Train Accuracy: 92.30%\n",
      " Validation Loss : 0.1437\t Validation Accuracy: 93.40%\n",
      "\n",
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 9\n",
      "Train Loss : 0.1671\t Train Accuracy: 92.90%\n",
      " Validation Loss : 0.1476\t Validation Accuracy: 93.50%\n",
      "\n",
      "\u001b[47m\u001b[31mEpochs: \u001b[0m 10\n",
      "Train Loss : 0.1654\t Train Accuracy: 92.60%\n",
      " Validation Loss : 0.1416\t Validation Accuracy: 92.90%\n",
      "\n",
      "\u001b[47m\u001b[36mEpochs: \u001b[0m 10\n",
      "test Loss : 0.1409\t test Accuracy: 94.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' ready for dataset'''\n",
    "n_train, n_validation, n_test = 1000, 300, 300\n",
    "\n",
    "train_x = np.random.normal(0, 1, size=(n_train, 1)).astype('float32')\n",
    "train_x_noise = train_x + 0.2 * np.random.normal(0, 1, size=(n_train, 1))\n",
    "train_y = (train_x_noise > 0).astype(np.int32)\n",
    "\n",
    "validation_x = np.random.normal(0, 1, size=(n_train, 1)).astype('float32')\n",
    "validation_x_noise = validation_x + 0.2 * np.random.normal(0, 1, size=(n_train, 1))\n",
    "validation_y = (validation_x_noise > 0).astype(np.int32)\n",
    "\n",
    "test_x = np.random.normal(0, 1, size=(n_train, 1)).astype('float32')\n",
    "test_x_noise = test_x + 0.2 * np.random.normal(0, 1, size=(n_train, 1))\n",
    "test_y = (test_x_noise > 0).astype(np.int32)\n",
    "\n",
    "\n",
    "''' split dataset'''\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "train_ds = train_ds.shuffle(n_train).batch(8)\n",
    "\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_x, validation_y))\n",
    "validation_ds = validation_ds.batch(n_validation)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_ds = test_ds.batch(n_test)\n",
    "\n",
    "\n",
    "''' parameter ready '''\n",
    "train_loss = Mean()\n",
    "train_acc = SparseCategoricalAccuracy()\n",
    "\n",
    "validation_loss = Mean()\n",
    "validation_acc = SparseCategoricalAccuracy()\n",
    "\n",
    "test_loss = Mean()\n",
    "test_acc = SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "''' modeling '''\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "loss_object = SparseCategoricalCrossentropy()\n",
    "optimizer = SGD(learning_rate=1)\n",
    "\n",
    "train_losses, validation_losses = [], []\n",
    "train_accs, validation_accs = [], []\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    global model, loss_object\n",
    "    global train_loss, train_acc\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_object(y, predictions)\n",
    "        \n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "    train_loss(loss)\n",
    "    train_acc(y, predictions)\n",
    "\n",
    "@tf.function\n",
    "def validation_step():\n",
    "    global validation_ds, model, loss_object\n",
    "    global train_loss, train_acc\n",
    "    \n",
    "    for x, y in validation_ds:\n",
    "        predictions = model(x)\n",
    "        loss = loss_object(y, predictions)\n",
    "        \n",
    "        validation_loss(loss)\n",
    "        validation_acc(y, predictions)\n",
    "\n",
    "# @tf.function        \n",
    "# def train_reporter():\n",
    "#     global epoch, train_loss, train_acc\n",
    "#     global valdiation_loss, validation_acc\n",
    "    \n",
    "#     print(colored('Epochs: ', 'red', 'on_white'), epoch + 1)\n",
    "#     template1 = f'Train Loss : {train_loss.result():.4f}\\t Train Accuracy: {train_acc.result()*100:.2f}%\\n' \n",
    "#     template2 = f'Validation Loss : {validation_loss.result():.4f}\\t Validation Accuracy: {validation_acc.result()*100:.2f}%\\n'\n",
    "    \n",
    "#     print(template1, template2)\n",
    "    # print(template.format(train_loss.result(), train_acc.result()*100, validation_loss.result(), validation_acc.result()*100))\n",
    "\n",
    "@tf.function\n",
    "def metric_resetter():\n",
    "    global train_losses, train_accs, train_loss, train_acc\n",
    "    global validation_losses, validation_accs, validation_loss, validation_acc\n",
    "    \n",
    "    train_losses.append(train_loss.result())\n",
    "    train_accs.append(train_acc.result())\n",
    "    validation_losses.append(validation_loss.result())\n",
    "    validation_accs.append(validation_acc.result())\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    validation_loss.reset_states()\n",
    "    validation_acc.reset_states()\n",
    "\n",
    "def final_result_visualization():\n",
    "    global train_losses, validation_losses\n",
    "    global train_acss, validation_accs\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(12, 8))\n",
    "    axes[0].plot(train_losses, label= 'Train Loss')\n",
    "    axes[0].plot(validation_losses, label='Validation Loss')\n",
    "    axes[1].plot(train_accs, label='Train Acc')\n",
    "    axes[1].plot(validation_losses, label='Valdiation Acc')\n",
    "    axes[0].tick_params(labelsize=13)\n",
    "    axes[1].tick_params(labelsize=13)\n",
    "    \n",
    "    axes[0].set_ylabel('Binary Cross Entropy', fontsize=13)\n",
    "    axes[1].set_ylabel('Accuracy', fontsize=13)\n",
    "    axes[1].set_xlabel('Epoch', fontsize=13)\n",
    "    \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for x, y in train_ds:\n",
    "        train_step(x, y)\n",
    "        \n",
    "    validation_step()\n",
    "    \n",
    "    print(colored('Epochs: ', 'red', 'on_white'), epoch + 1)\n",
    "    template1 = f'Train Loss : {train_loss.result():.4f}\\t Train Accuracy: {train_acc.result()*100:.2f}%\\n' \n",
    "    template2 = f'Validation Loss : {validation_loss.result():.4f}\\t Validation Accuracy: {validation_acc.result()*100:.2f}%\\n'\n",
    "    \n",
    "    print(template1, template2)\n",
    "    \n",
    "    metric_resetter()\n",
    "\n",
    "''' test set '''\n",
    "for x, y in test_ds:\n",
    "    predictions = model(x)\n",
    "    loss = loss_object(y, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_acc(y, predictions)\n",
    "\n",
    "print(colored('Epochs: ', 'cyan', 'on_white'), epoch + 1)\n",
    "template = 'test Loss : {:.4f}\\t test Accuracy: {:.2f}%\\n'\n",
    "\n",
    "print(template.format(test_loss.result(), test_acc.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192845b3-c5e6-4f57-949e-70bcc1d918fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
