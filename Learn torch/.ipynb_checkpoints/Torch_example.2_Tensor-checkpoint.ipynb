{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a5ea4c-1a34-4c77-ac1f-d8a3070f019b",
   "metadata": {},
   "source": [
    "# 텐서\n",
    "텐서는 배열이나 행렬과 매우 유사한 특수한 자료구조입니다. PyTorch에서는 텐서를 사용하여 모델의 입력과 출력, 그리고 모델의 매개변수들을 부호화(decode)합니다.\n",
    "\n",
    "텐서는 GPU나 다른 하드웨어 가속기에서 실행할 수 있다는 점만 제외하면 Numpy의 ndarray와 유사합니다. 실제로 텐서와 ndarray는 종종 동일한 내부(underly) 메모리를 공유할 수 있어 데이터를 여럿 만들 필요가 없습니다. 텐서는 또한 자동 미분(automatic differentiation)에 최적화되어있습니다. ndarray에 익숙하다면 Tensor API를 바로 사용할 수 있을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b164afb3-99e4-44ec-9761-2319daf2d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d0ecd-3511-4233-8f7b-18ad7f67cdf0",
   "metadata": {},
   "source": [
    "## 텐서 초기화\n",
    "텐서는 여러가지 방법으로 초기화할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bdac53-999d-4892-9e9b-7892ba372eba",
   "metadata": {},
   "source": [
    "### 직접 생성하기\n",
    "데이터의 자료형은 자동으로 유추합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23d737e-529c-41f6-b20b-cdc898360fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d37354-1ece-4443-a762-cbb95e012d7d",
   "metadata": {},
   "source": [
    "### Numpy 배열로부터 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea843ccb-466a-4720-9331-f8a5d8cb414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3811ed2e-f35b-41b6-93de-9769a80f48f2",
   "metadata": {},
   "source": [
    "### 다른 텐서로부터 생성하기\n",
    "명시적으로 재정의(override)하지 않는다면, 인자로 주어진 텐서의 속성(모양, 자료형)을 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2ac769-8ff2-4b57-b491-03be900076da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.5769, 0.4251],\n",
      "        [0.2936, 0.1371]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지합니다.\n",
    "print(f'Ones Tensor: \\n {x_ones} \\n')\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)  # x_data의 속성을 덮어씁니다\n",
    "print(f'Random Tensor: \\n {x_rand} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c22931-a778-4c2f-b670-05fdf5863469",
   "metadata": {},
   "source": [
    "### 무작위 또는 상수값을 사용하기 ( random or constant )\n",
    "shape은 텐서의 차원을 나타내는 튜플로, 아래 함수들에서는 출력 텐서의 차원을 결정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbd2c6d2-c4ab-4f97-96e2-f55280812714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor : \n",
      "tensor([[0.0460, 0.2060, 0.3166],\n",
      "        [0.9046, 0.0855, 0.9277]]) \n",
      "\n",
      "Ones Tensor : \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor : \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f'Random Tensor : \\n{rand_tensor} \\n')\n",
    "print(f'Ones Tensor : \\n{ones_tensor} \\n')\n",
    "print(f'Zeros Tensor : \\n{zeros_tensor} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b809e-9b36-4572-a50a-009a1dbc08f2",
   "metadata": {},
   "source": [
    "## 텐서의 속성 ( Attribute )\n",
    "텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93358fb5-3a01-4b64-bb48-f24a21b5192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensor : torch.Size([3, 4])\n",
      "datatype of tensor : torch.float32\n",
      "Device tensor is stored on : cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f'shape of tensor : {tensor.shape}')\n",
    "print(f'datatype of tensor : {tensor.dtype}')\n",
    "print(f'Device tensor is stored on : {tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6857fc-5f7d-438e-a9d6-09c6787c36b2",
   "metadata": {},
   "source": [
    "## 텐서 연산 ( Operation )\n",
    "전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수, 임의 샘플링 등 100가지 텐서 연산들은 https://pytorch.org/docs/stable/torch.html 에서 확인할 수 있습니다\n",
    "\n",
    "각 연산들은(일반적으로) GPU에서 실행할 수 있습니다. Colab에서는 Notebook Settings에서 GPU를 할당할 수 있습니다.\n",
    "\n",
    "기본적으로 텐서는 CPU에 생성되니다. .to 메서드를 사용하면 (GPU의 가용성을 확인한 뒤) GPU로 텐서를 명시적으로 이동할 수 있습니다. 장치들 간에 큰 텐서들을 복사하는 것은 시간과 메모리 측면에서 비용이 많이 든다는 것을 기억해야합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66d4994-0143-4217-81da-592d929c1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU가 존재하면 텐서를 이동합니다.\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352413ee-c61b-497b-9dcd-7a2902c73056",
   "metadata": {},
   "source": [
    "Numpy와 유사한 방식으로 몇몇 텐서 연산을 시도해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bef816f-4d38-4537-a71f-5e30e58b1ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(tensor, '\\n')\n",
    "tensor[:, 1] = 0\n",
    "print(tensor, '\\n')\n",
    "tensor[1, :] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4024990-8527-4e4f-97ec-6aa3570e2586",
   "metadata": {},
   "source": [
    "<font color=green>__텐서 합치기__</font> torch.cat을 사용하여 주어진 차원에 따라 일련의 텐서를 연결할 수 있습니다. torch.cat과 미묘하게 다른 결합 연산인 torch.stack도 실습해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1341d1ef-29ad-4cc7-9312-0010690d9342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "torch.Size([12, 4])\n"
     ]
    }
   ],
   "source": [
    "# 0 = x = row // row단위로 해당 텐서들을 합침 ( 차원은 그대로 )\n",
    "t0 = torch.cat([tensor, tensor, tensor], dim=0)\n",
    "print(t0)\n",
    "print(t0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f65b78af-44a6-4d55-8877-b8443996eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "# 1 = y = col // col단위로 해당 텐서들을 합침 ( 차원은 그대로 )\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85bfdf00-2683-4cbf-a619-ca73f82d905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 1., 1.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]]])\n",
      "torch.Size([3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# 해당 텐서들을 개수만큼 새로운 차원의 요소로 합침\n",
    "## (4, 4) 크기 tensor 3개를 묶으면 (3, 4, 4)\n",
    "t2 = torch.stack([tensor, tensor, tensor])\n",
    "print(t2)\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "710b6bd4-ae65-4ccf-80b5-bdc0ea1e434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 1., 1.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [1., 0., 1., 1.],\n",
      "          [1., 0., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 1., 1.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [1., 0., 1., 1.],\n",
      "          [1., 0., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 1., 1.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [1., 0., 1., 1.],\n",
      "          [1., 0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1., 1.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [1., 0., 1., 1.],\n",
      "          [1., 0., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 1., 1.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [1., 0., 1., 1.],\n",
      "          [1., 0., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 1., 1.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [1., 0., 1., 1.],\n",
      "          [1., 0., 1., 1.]]]])\n",
      "torch.Size([2, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.stack([t2, t2])\n",
    "print(t3)\n",
    "print(t3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476eada1-6ad0-43f2-9d5d-10a1d7d2d309",
   "metadata": {},
   "source": [
    "## 산술 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "099b7759-000a-43ce-9f6d-8e5aa5ec1137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 0., 3., 3.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
    "y1 = tensor @ tensor.T    \n",
    "# 행렬곱(예시)은 4x3 * 3x2 = 4x2가 나온다. \n",
    "# (a의 ncol과 b의 nrow가 같음을 가정하므로 행렬변환 T를 적용함 )\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "print(y1)\n",
    "\n",
    "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "print(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8c568be-ea68-44cc-9db1-9cab878aa04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 0., 9., 9.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [9., 0., 9., 9.],\n",
       "        [9., 0., 9., 9.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ y1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd77ad-b6e4-4b1c-a438-18cec699b9b9",
   "metadata": {},
   "source": [
    "단일-요소(single-element) 텐서\n",
    "- 텐서의 모든 값을 하나로 집계(aggregate)하여 요소가 하나인 텐서의 경우, item()을 사용하여 Python 숫자 값으로 변환할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c7c242a-0cce-4c5f-95cc-ed1f8333f71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331c3dc-72c3-49cc-9553-43f53771550f",
   "metadata": {},
   "source": [
    "__바꿔치기(in_place) 연산__ 연산 결과를 피연산자(operand)에 저장하는 연산을 바꿔치기 연산이라고 부르며, \\_ 접미사를 갖습니다. 예를 들어: x.copy_(y)나 x.t_()는 x를 변경합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "477c0570-1350-4b61-a3f5-2272b0457409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, '\\n')\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64f10a8a-5e91-4ee7-89a9-11f398f377f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[133., 115., 133., 133.],\n",
       "        [115., 100., 115., 115.],\n",
       "        [133., 115., 133., 133.],\n",
       "        [133., 115., 133., 133.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037d0918-bff9-4769-9ca6-8ec80e16f0b9",
   "metadata": {},
   "source": [
    "## Numpy 변환 ( Bridge )\n",
    "CPU 상의 텐서와 Numpy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경됩니다.\n",
    "### 텐서를 Numpy 배열로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2879f8a-d6f5-4e1e-b4cc-b571db708f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f't: {t}')\n",
    "n = t.numpy()\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8d680-00b9-4878-89d1-aa2ba5e98f44",
   "metadata": {},
   "source": [
    "텐서에 수정을 가하면, 같은 메모리 공간을 공유하는 ndarray도 값이 수정됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2371440b-7cc0-48bf-a945-3a710313d870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(2)\n",
    "print(t)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a20a74-fa83-47b2-aa00-932c01ab1946",
   "metadata": {},
   "source": [
    "### Numpy 배열을 텐서로 변환하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0987f0e-1f28-41e4-9dd1-38fe6b1ec7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] \n",
      " tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "print(n, '\\n', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51be504-99c3-43ee-9e52-73a9e397fbe4",
   "metadata": {},
   "source": [
    "텐서를 수정하면 넘파이배열의 값이 바뀐 것과 마찬가지로,\n",
    "\n",
    "넘파이배열에 수정을 가하면 텐서 또한 수정됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f07d7a25-cc3e-47d9-9291-8f7a6055298b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3. 3.] \n",
      " tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 2, out=n)\n",
    "print(n, '\\n', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda94c04-f86c-4c1d-a0a2-64d07c73f239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
